import pandas as pd
import ingest
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_community.vectorstores import SKLearnVectorStore
from langchain_ollama import ChatOllama, OllamaEmbeddings
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

cards_df = pd.read_csv('rules_rag/data/cleaned_cards.csv')

# Directory containing data files
with open('rules_rag/data/MagicCompRules_20260116.txt', 'r', encoding='utf-8') as file:
    rules = file.read()
    rules_list = rules.split('\n\n')

embedding = OllamaEmbeddings(model="nomic-embed-text")

# Create embeddings for documents and store them in a vector store
print("Embedding chunks...")
vectorstore = ingest.get_or_build_vectorstore(rules_list, embedding)
print("Chunks embeded.")

retriever = vectorstore.as_retriever(k=5)

prompt = PromptTemplate.from_template(
    """
    You are an expert-level Magic: The Gathering rules judge.

    You answer questions strictly using the provided context from the official Comprehensive Rules document.
    You do not rely on outside knowledge.
    If the answer is not fully supported by the provided rules context, you must say:
    "I cannot determine the ruling from the provided rules context."

    Your task:
    Given a game scenario or rules question, determine the correct ruling using only the provided rules excerpts.

    Instructions:

    1. Carefully analyze the scenario.
    2. Identify which rules apply.
    3. Quote the relevant rule numbers and text.
    4. Explain step-by-step how those rules apply to the situation.
    5. Provide a clear final ruling.

    If the scenario is ambiguous or missing required details:
    - Explicitly state what information is missing.
    - Explain how the ruling could change depending on that missing information.

    Formatting Requirements:

    Answer in this structure:

    **Relevant Rules**
    - Rule [number]: "Quoted rule text"
    - Rule [number]: "Quoted rule text"

    **Analysis**
    Step-by-step explanation applying the rules to the scenario.

    **Final Ruling**
    A clear, concise statement of what happens in the game.

    Context from the Comprehensive Rules:
    {context}

    Question:
    {question}
    """
)

# Initialize the LLM with Llama 3.1 model
llm = ChatOllama(
    model="llama3.1",
    temperature=0.8,
)

# Create a chain combining the prompt template and LLM
rag_chain = {"context": retriever, "question": RunnablePassthrough()
             } | prompt | llm | StrOutputParser()


def get_card_info(card_names, cards_df):
    card_input_data = []
    for name in card_names:
        card_data = cards_df[cards_df['name'] == name].iloc[0].to_dict()

        card_info = []
        wanted_card_info = ['name', 'oracle_text']
        for wanted_info in wanted_card_info:
            information = card_data.get(wanted_info)
            card_info.append(information)
        card_data = f"{card_info[0]}: {card_info[1]}"
        card_input_data.append(card_data)

    return card_input_data


running = True
while running:
    cards_input = input("Enter cards (separate with '/'): ")
    cards_list = cards_input.split('/')
    cards = get_card_info(cards_list, cards_df)
    question = f"How could these cards interact with each other? Cards: {cards}"
    if question == 'quit':
        running = False
    else:
        answer = rag_chain.invoke(question)
        print("Answer:", answer)
    print(150*"=")
